{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "initial_dataset = load_dataset('AI-MO/NuminaMath-CoT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "import torch\n",
    "from transformer_lens import HookedTransformer  # type: ignore\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer  # type: ignore\n",
    "\n",
    "from model_diffing.scripts.config_common import LLMConfig\n",
    "\n",
    "def build_llm(\n",
    "        hf_model_id: str):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        hf_model_id\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "\n",
    "\n",
    "# load models for generating new dataset\n",
    "\n",
    "r1_distil = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'\n",
    "qwen_math = 'Qwen/Qwen2.5-Math-1.5B'\n",
    "\n",
    "# load these as HookedTransformers\n",
    "r1_model = build_llm(r1_distil)\n",
    "qwen_model = build_llm(qwen_math)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', padding_side='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "\n",
    "def batch_get_responses(model, problems, batch_size=4, add_think=False):\n",
    "    responses = []\n",
    "    \n",
    "    # Create batches\n",
    "    for i in range(0, len(problems), batch_size):\n",
    "        batch_problems = problems[i:i + batch_size]\n",
    "        \n",
    "        # Add think token if needed\n",
    "        if add_think:\n",
    "            batch_problems = [p + ' <think>\\n' for p in batch_problems]\n",
    "            \n",
    "        # Tokenize batch\n",
    "        batch_inputs = tokenizer(\n",
    "            batch_problems, \n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        ).to('cuda')\n",
    "        \n",
    "        # Generate responses\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **batch_inputs,\n",
    "                max_new_tokens=528,\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "            )\n",
    "            \n",
    "        # Decode responses\n",
    "        batch_responses = [\n",
    "            tokenizer.decode(output, skip_special_tokens=True) \n",
    "            for output in outputs\n",
    "        ]\n",
    "        responses.extend(batch_responses)\n",
    "        \n",
    "        del batch_inputs, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return responses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def gen_model_responses(problems, batch_size=4):\\n    \"\"\"Generator that yields alternating R1 and Qwen responses for each problem\"\"\"\\n    \\n    # Move models to CPU initially\\n    \\n    with tqdm(total=len(problems)*2, desc=\"Generating responses\") as pbar:\\n        for i in range(0, len(problems), batch_size):\\n            # Get current batch\\n            batch_problems = problems[i:i + batch_size]\\n            \\n            # Process batch and get responses\\n            r1_responses, qwen_responses = process_batch(batch_problems, batch_size)\\n            \\n            if not r1_responses or not qwen_responses:\\n                print(f\"Skipping batch {i} due to error\")\\n                continue\\n                \\n            # Yield alternating responses\\n            for j, (problem, r1_resp, qwen_resp) in enumerate(zip(batch_problems, r1_responses, qwen_responses)):\\n                # Yield R1 response\\n                yield {\\n                    \\'problem\\': problem,\\n                    \\'text\\': r1_resp,\\n                    \\'model\\': \\'r1\\'\\n                }\\n                pbar.update(1)\\n                \\n                # Yield Qwen response\\n                yield {\\n                    \\'problem\\': problem,\\n                    \\'text\\': qwen_resp,\\n                    \\'model\\': \\'qwen\\'\\n                }\\n                pbar.update(1)\\n            \\n            # Force garbage collection after each batch\\n            del r1_responses\\n            del qwen_responses\\n            del batch_problems\\n            gc.collect()\\n            torch.cuda.empty_cache()\\n            \\n            # Add an explicit pause between batches to allow memory cleanup\\n            import time\\n            time.sleep(0.5)\\n\\n\\n\\nproblems = initial_dataset[\\'train\\'][\\'problem\\'][:7680]\\n# Create dataset using generator\\ncombined_dataset = Dataset.from_generator(\\n    lambda: gen_model_responses(problems, batch_size=128)  # Reduced batch size\\n)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datasets import Dataset\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import Dataset\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Define a function outside the generator to handle a single batch\n",
    "def process_batch(batch_problems, batch_size):\n",
    "    try:\n",
    "        r1_responses = batch_get_responses(r1_model, batch_problems, batch_size=batch_size, add_think=True)\n",
    "        # Convert to simple Python objects if needed\n",
    "        r1_responses = [str(r) for r in r1_responses]  # Ensure they're strings\n",
    "        \n",
    "        # Clear CUDA cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Qwen generation\n",
    "        qwen_responses = batch_get_responses(qwen_model, batch_problems, batch_size=batch_size)\n",
    "        # Convert to simple Python objects if needed\n",
    "        qwen_responses = [str(q) for q in qwen_responses]  # Ensure they're strings\n",
    "        \n",
    "        # Clear CUDA cache again\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return r1_responses, qwen_responses\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {e}\")\n",
    "        # Return empty lists if there's an error\n",
    "        return [], []\n",
    "\n",
    "'''def gen_model_responses(problems, batch_size=4):\n",
    "    \"\"\"Generator that yields alternating R1 and Qwen responses for each problem\"\"\"\n",
    "    \n",
    "    # Move models to CPU initially\n",
    "    \n",
    "    with tqdm(total=len(problems)*2, desc=\"Generating responses\") as pbar:\n",
    "        for i in range(0, len(problems), batch_size):\n",
    "            # Get current batch\n",
    "            batch_problems = problems[i:i + batch_size]\n",
    "            \n",
    "            # Process batch and get responses\n",
    "            r1_responses, qwen_responses = process_batch(batch_problems, batch_size)\n",
    "            \n",
    "            if not r1_responses or not qwen_responses:\n",
    "                print(f\"Skipping batch {i} due to error\")\n",
    "                continue\n",
    "                \n",
    "            # Yield alternating responses\n",
    "            for j, (problem, r1_resp, qwen_resp) in enumerate(zip(batch_problems, r1_responses, qwen_responses)):\n",
    "                # Yield R1 response\n",
    "                yield {\n",
    "                    'problem': problem,\n",
    "                    'text': r1_resp,\n",
    "                    'model': 'r1'\n",
    "                }\n",
    "                pbar.update(1)\n",
    "                \n",
    "                # Yield Qwen response\n",
    "                yield {\n",
    "                    'problem': problem,\n",
    "                    'text': qwen_resp,\n",
    "                    'model': 'qwen'\n",
    "                }\n",
    "                pbar.update(1)\n",
    "            \n",
    "            # Force garbage collection after each batch\n",
    "            del r1_responses\n",
    "            del qwen_responses\n",
    "            del batch_problems\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Add an explicit pause between batches to allow memory cleanup\n",
    "            import time\n",
    "            time.sleep(0.5)\n",
    "\n",
    "\n",
    "\n",
    "problems = initial_dataset['train']['problem'][:7680]\n",
    "# Create dataset using generator\n",
    "combined_dataset = Dataset.from_generator(\n",
    "    lambda: gen_model_responses(problems, batch_size=128)  # Reduced batch size\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743af25406b34708a3abbf799c5a740a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0, problems 0 to 15\n",
      "Processing batch 1, problems 16 to 31\n",
      "Processing batch 2, problems 32 to 47\n",
      "Processing batch 3, problems 48 to 63\n",
      "Processing batch 4, problems 64 to 79\n",
      "Processing batch 5, problems 80 to 95\n",
      "Processing batch 6, problems 96 to 111\n",
      "Processing batch 7, problems 112 to 127\n",
      "Processing batch 8, problems 128 to 143\n",
      "Processing batch 9, problems 144 to 159\n",
      "Processing batch 10, problems 160 to 175\n",
      "Processing batch 11, problems 176 to 191\n",
      "Processing batch 12, problems 192 to 207\n",
      "Processing batch 13, problems 208 to 223\n",
      "Processing batch 14, problems 224 to 239\n",
      "Processing batch 15, problems 240 to 255\n",
      "Processing batch 16, problems 256 to 271\n",
      "Processing batch 17, problems 272 to 287\n",
      "Processing batch 18, problems 288 to 303\n",
      "Processing batch 19, problems 304 to 319\n",
      "Processing batch 20, problems 320 to 335\n",
      "Processing batch 21, problems 336 to 351\n",
      "Processing batch 22, problems 352 to 367\n",
      "Processing batch 23, problems 368 to 383\n",
      "Processing batch 24, problems 384 to 399\n",
      "Processing batch 25, problems 400 to 415\n",
      "Processing batch 26, problems 416 to 431\n",
      "Processing batch 27, problems 432 to 447\n",
      "Processing batch 28, problems 448 to 463\n",
      "Processing batch 29, problems 464 to 479\n",
      "Processing batch 30, problems 480 to 495\n",
      "Processing batch 31, problems 496 to 511\n",
      "Processing batch 32, problems 512 to 527\n",
      "Processing batch 33, problems 528 to 543\n",
      "Processing batch 34, problems 544 to 559\n",
      "Processing batch 35, problems 560 to 575\n",
      "Processing batch 36, problems 576 to 591\n",
      "Processing batch 37, problems 592 to 607\n",
      "Processing batch 38, problems 608 to 623\n",
      "Processing batch 39, problems 624 to 639\n",
      "Processing batch 40, problems 640 to 655\n",
      "Processing batch 41, problems 656 to 671\n",
      "Processing batch 42, problems 672 to 687\n",
      "Processing batch 43, problems 688 to 703\n",
      "Processing batch 44, problems 704 to 719\n",
      "Processing batch 45, problems 720 to 735\n",
      "Processing batch 46, problems 736 to 751\n",
      "Processing batch 47, problems 752 to 767\n",
      "Processing batch 48, problems 768 to 783\n",
      "Processing batch 49, problems 784 to 799\n",
      "Processing batch 50, problems 800 to 815\n",
      "Processing batch 51, problems 816 to 831\n",
      "Processing batch 52, problems 832 to 847\n",
      "Processing batch 53, problems 848 to 863\n",
      "Processing batch 54, problems 864 to 879\n",
      "Processing batch 55, problems 880 to 895\n",
      "Processing batch 56, problems 896 to 911\n",
      "Processing batch 57, problems 912 to 927\n",
      "Processing batch 58, problems 928 to 943\n",
      "Processing batch 59, problems 944 to 959\n",
      "Processing batch 60, problems 960 to 975\n",
      "Processing batch 61, problems 976 to 991\n",
      "Processing batch 62, problems 992 to 1007\n",
      "Processing batch 63, problems 1008 to 1023\n",
      "Processing batch 64, problems 1024 to 1039\n",
      "Processing batch 65, problems 1040 to 1055\n",
      "Processing batch 66, problems 1056 to 1071\n",
      "Processing batch 67, problems 1072 to 1087\n",
      "Processing batch 68, problems 1088 to 1103\n",
      "Processing batch 69, problems 1104 to 1119\n",
      "Processing batch 70, problems 1120 to 1135\n",
      "Processing batch 71, problems 1136 to 1151\n",
      "Processing batch 72, problems 1152 to 1167\n",
      "Processing batch 73, problems 1168 to 1183\n",
      "Processing batch 74, problems 1184 to 1199\n",
      "Processing batch 75, problems 1200 to 1215\n",
      "Processing batch 76, problems 1216 to 1231\n",
      "Processing batch 77, problems 1232 to 1247\n",
      "Processing batch 78, problems 1248 to 1263\n",
      "Processing batch 79, problems 1264 to 1279\n",
      "Processing batch 80, problems 1280 to 1295\n",
      "Processing batch 81, problems 1296 to 1311\n",
      "Processing batch 82, problems 1312 to 1327\n",
      "Processing batch 83, problems 1328 to 1343\n",
      "Processing batch 84, problems 1344 to 1359\n",
      "Processing batch 85, problems 1360 to 1375\n",
      "Processing batch 86, problems 1376 to 1391\n",
      "Processing batch 87, problems 1392 to 1407\n",
      "Processing batch 88, problems 1408 to 1423\n",
      "Processing batch 89, problems 1424 to 1439\n",
      "Processing batch 90, problems 1440 to 1455\n",
      "Processing batch 91, problems 1456 to 1471\n",
      "Processing batch 92, problems 1472 to 1487\n",
      "Processing batch 93, problems 1488 to 1503\n",
      "Processing batch 94, problems 1504 to 1519\n",
      "Processing batch 95, problems 1520 to 1535\n",
      "Processing batch 96, problems 1536 to 1551\n",
      "Processing batch 97, problems 1552 to 1567\n",
      "Processing batch 98, problems 1568 to 1583\n",
      "Processing batch 99, problems 1584 to 1599\n",
      "Processing batch 100, problems 1600 to 1615\n",
      "Processing batch 101, problems 1616 to 1631\n",
      "Processing batch 102, problems 1632 to 1647\n",
      "Processing batch 103, problems 1648 to 1663\n",
      "Processing batch 104, problems 1664 to 1679\n",
      "Processing batch 105, problems 1680 to 1695\n",
      "Processing batch 106, problems 1696 to 1711\n",
      "Processing batch 107, problems 1712 to 1727\n",
      "Processing batch 108, problems 1728 to 1743\n",
      "Processing batch 109, problems 1744 to 1759\n",
      "Processing batch 110, problems 1760 to 1775\n",
      "Processing batch 111, problems 1776 to 1791\n",
      "Processing batch 112, problems 1792 to 1807\n",
      "Processing batch 113, problems 1808 to 1823\n",
      "Processing batch 114, problems 1824 to 1839\n",
      "Processing batch 115, problems 1840 to 1855\n",
      "Processing batch 116, problems 1856 to 1871\n",
      "Processing batch 117, problems 1872 to 1887\n",
      "Processing batch 118, problems 1888 to 1903\n",
      "Processing batch 119, problems 1904 to 1919\n",
      "Processing batch 120, problems 1920 to 1935\n",
      "Processing batch 121, problems 1936 to 1951\n",
      "Processing batch 122, problems 1952 to 1967\n",
      "Processing batch 123, problems 1968 to 1983\n",
      "Processing batch 124, problems 1984 to 1999\n",
      "Processing batch 125, problems 2000 to 2015\n",
      "Processing batch 126, problems 2016 to 2031\n",
      "Processing batch 127, problems 2032 to 2047\n",
      "Processing batch 128, problems 2048 to 2063\n",
      "Processing batch 129, problems 2064 to 2079\n",
      "Processing batch 130, problems 2080 to 2095\n",
      "Processing batch 131, problems 2096 to 2111\n",
      "Processing batch 132, problems 2112 to 2127\n",
      "Processing batch 133, problems 2128 to 2143\n",
      "Processing batch 134, problems 2144 to 2159\n",
      "Processing batch 135, problems 2160 to 2175\n",
      "Processing batch 136, problems 2176 to 2191\n",
      "Processing batch 137, problems 2192 to 2207\n",
      "Processing batch 138, problems 2208 to 2223\n",
      "Processing batch 139, problems 2224 to 2239\n",
      "Processing batch 140, problems 2240 to 2255\n",
      "Processing batch 141, problems 2256 to 2271\n",
      "Processing batch 142, problems 2272 to 2287\n",
      "Processing batch 143, problems 2288 to 2303\n",
      "Processing batch 144, problems 2304 to 2319\n",
      "Processing batch 145, problems 2320 to 2335\n",
      "Processing batch 146, problems 2336 to 2351\n",
      "Processing batch 147, problems 2352 to 2367\n",
      "Processing batch 148, problems 2368 to 2383\n",
      "Processing batch 149, problems 2384 to 2399\n",
      "Processing batch 150, problems 2400 to 2415\n",
      "Processing batch 151, problems 2416 to 2431\n",
      "Processing batch 152, problems 2432 to 2447\n",
      "Processing batch 153, problems 2448 to 2463\n",
      "Processing batch 154, problems 2464 to 2479\n",
      "Processing batch 155, problems 2480 to 2495\n",
      "Processing batch 156, problems 2496 to 2511\n",
      "Processing batch 157, problems 2512 to 2527\n",
      "Processing batch 158, problems 2528 to 2543\n",
      "Processing batch 159, problems 2544 to 2559\n",
      "Processing batch 160, problems 2560 to 2575\n",
      "Processing batch 161, problems 2576 to 2591\n",
      "Processing batch 162, problems 2592 to 2607\n",
      "Processing batch 163, problems 2608 to 2623\n",
      "Processing batch 164, problems 2624 to 2639\n",
      "Processing batch 165, problems 2640 to 2655\n",
      "Processing batch 166, problems 2656 to 2671\n",
      "Processing batch 167, problems 2672 to 2687\n",
      "Processing batch 168, problems 2688 to 2703\n",
      "Processing batch 169, problems 2704 to 2719\n",
      "Processing batch 170, problems 2720 to 2735\n",
      "Processing batch 171, problems 2736 to 2751\n",
      "Processing batch 172, problems 2752 to 2767\n",
      "Processing batch 173, problems 2768 to 2783\n",
      "Processing batch 174, problems 2784 to 2799\n",
      "Processing batch 175, problems 2800 to 2815\n",
      "Processing batch 176, problems 2816 to 2831\n",
      "Processing batch 177, problems 2832 to 2847\n",
      "Processing batch 178, problems 2848 to 2863\n",
      "Processing batch 179, problems 2864 to 2879\n",
      "Processing batch 180, problems 2880 to 2895\n",
      "Processing batch 181, problems 2896 to 2911\n",
      "Processing batch 182, problems 2912 to 2927\n",
      "Processing batch 183, problems 2928 to 2943\n",
      "Processing batch 184, problems 2944 to 2959\n",
      "Processing batch 185, problems 2960 to 2975\n",
      "Processing batch 186, problems 2976 to 2991\n",
      "Processing batch 187, problems 2992 to 3007\n",
      "Processing batch 188, problems 3008 to 3023\n",
      "Processing batch 189, problems 3024 to 3039\n",
      "Processing batch 190, problems 3040 to 3055\n",
      "Processing batch 191, problems 3056 to 3071\n",
      "Processing batch 192, problems 3072 to 3087\n",
      "Processing batch 193, problems 3088 to 3103\n",
      "Processing batch 194, problems 3104 to 3119\n",
      "Processing batch 195, problems 3120 to 3135\n",
      "Processing batch 196, problems 3136 to 3151\n",
      "Processing batch 197, problems 3152 to 3167\n",
      "Processing batch 198, problems 3168 to 3183\n",
      "Processing batch 199, problems 3184 to 3199\n",
      "Processing batch 200, problems 3200 to 3215\n",
      "Processing batch 201, problems 3216 to 3231\n",
      "Processing batch 202, problems 3232 to 3247\n",
      "Processing batch 203, problems 3248 to 3263\n",
      "Processing batch 204, problems 3264 to 3279\n",
      "Processing batch 205, problems 3280 to 3295\n",
      "Processing batch 206, problems 3296 to 3311\n",
      "Processing batch 207, problems 3312 to 3327\n",
      "Processing batch 208, problems 3328 to 3343\n",
      "Processing batch 209, problems 3344 to 3359\n",
      "Processing batch 210, problems 3360 to 3375\n",
      "Processing batch 211, problems 3376 to 3391\n",
      "Processing batch 212, problems 3392 to 3407\n",
      "Processing batch 213, problems 3408 to 3423\n",
      "Processing batch 214, problems 3424 to 3439\n",
      "Processing batch 215, problems 3440 to 3455\n",
      "Processing batch 216, problems 3456 to 3471\n",
      "Processing batch 217, problems 3472 to 3487\n",
      "Processing batch 218, problems 3488 to 3503\n",
      "Processing batch 219, problems 3504 to 3519\n",
      "Processing batch 220, problems 3520 to 3535\n",
      "Processing batch 221, problems 3536 to 3551\n",
      "Processing batch 222, problems 3552 to 3567\n",
      "Processing batch 223, problems 3568 to 3583\n",
      "Processing batch 224, problems 3584 to 3599\n",
      "Processing batch 225, problems 3600 to 3615\n",
      "Processing batch 226, problems 3616 to 3631\n",
      "Processing batch 227, problems 3632 to 3647\n",
      "Processing batch 228, problems 3648 to 3663\n",
      "Processing batch 229, problems 3664 to 3679\n",
      "Processing batch 230, problems 3680 to 3695\n",
      "Processing batch 231, problems 3696 to 3711\n",
      "Processing batch 232, problems 3712 to 3727\n",
      "Processing batch 233, problems 3728 to 3743\n",
      "Processing batch 234, problems 3744 to 3759\n",
      "Processing batch 235, problems 3760 to 3775\n",
      "Processing batch 236, problems 3776 to 3791\n",
      "Processing batch 237, problems 3792 to 3807\n",
      "Processing batch 238, problems 3808 to 3823\n",
      "Processing batch 239, problems 3824 to 3839\n",
      "Processing batch 240, problems 3840 to 3855\n",
      "Processing batch 241, problems 3856 to 3871\n",
      "Processing batch 242, problems 3872 to 3887\n",
      "Processing batch 243, problems 3888 to 3903\n",
      "Processing batch 244, problems 3904 to 3919\n",
      "Processing batch 245, problems 3920 to 3935\n",
      "Processing batch 246, problems 3936 to 3951\n",
      "Processing batch 247, problems 3952 to 3967\n",
      "Processing batch 248, problems 3968 to 3983\n",
      "Processing batch 249, problems 3984 to 3999\n",
      "Processing batch 250, problems 4000 to 4015\n",
      "Processing batch 251, problems 4016 to 4031\n",
      "Processing batch 252, problems 4032 to 4047\n",
      "Processing batch 253, problems 4048 to 4063\n",
      "Processing batch 254, problems 4064 to 4079\n",
      "Processing batch 255, problems 4080 to 4095\n",
      "Processing batch 256, problems 4096 to 4111\n",
      "Processing batch 257, problems 4112 to 4127\n",
      "Processing batch 258, problems 4128 to 4143\n",
      "Processing batch 259, problems 4144 to 4159\n",
      "Processing batch 260, problems 4160 to 4175\n",
      "Processing batch 261, problems 4176 to 4191\n",
      "Processing batch 262, problems 4192 to 4207\n",
      "Processing batch 263, problems 4208 to 4223\n",
      "Processing batch 264, problems 4224 to 4239\n",
      "Processing batch 265, problems 4240 to 4255\n",
      "Processing batch 266, problems 4256 to 4271\n",
      "Processing batch 267, problems 4272 to 4287\n",
      "Processing batch 268, problems 4288 to 4303\n",
      "Processing batch 269, problems 4304 to 4319\n",
      "Processing batch 270, problems 4320 to 4335\n",
      "Processing batch 271, problems 4336 to 4351\n",
      "Processing batch 272, problems 4352 to 4367\n",
      "Processing batch 273, problems 4368 to 4383\n",
      "Processing batch 274, problems 4384 to 4399\n",
      "Processing batch 275, problems 4400 to 4415\n",
      "Processing batch 276, problems 4416 to 4431\n",
      "Processing batch 277, problems 4432 to 4447\n",
      "Processing batch 278, problems 4448 to 4463\n",
      "Processing batch 279, problems 4464 to 4479\n",
      "Processing batch 280, problems 4480 to 4495\n",
      "Processing batch 281, problems 4496 to 4511\n",
      "Processing batch 282, problems 4512 to 4527\n",
      "Processing batch 283, problems 4528 to 4543\n",
      "Processing batch 284, problems 4544 to 4559\n",
      "Processing batch 285, problems 4560 to 4575\n",
      "Processing batch 286, problems 4576 to 4591\n",
      "Processing batch 287, problems 4592 to 4607\n",
      "Processing batch 288, problems 4608 to 4623\n",
      "Processing batch 289, problems 4624 to 4639\n",
      "Processing batch 290, problems 4640 to 4655\n",
      "Processing batch 291, problems 4656 to 4671\n",
      "Processing batch 292, problems 4672 to 4687\n",
      "Processing batch 293, problems 4688 to 4703\n",
      "Processing batch 294, problems 4704 to 4719\n",
      "Processing batch 295, problems 4720 to 4735\n",
      "Processing batch 296, problems 4736 to 4751\n",
      "Processing batch 297, problems 4752 to 4767\n",
      "Processing batch 298, problems 4768 to 4783\n",
      "Processing batch 299, problems 4784 to 4799\n",
      "Processing batch 300, problems 4800 to 4815\n",
      "Processing batch 301, problems 4816 to 4831\n",
      "Processing batch 302, problems 4832 to 4847\n",
      "Processing batch 303, problems 4848 to 4863\n",
      "Processing batch 304, problems 4864 to 4879\n",
      "Processing batch 305, problems 4880 to 4895\n",
      "Processing batch 306, problems 4896 to 4911\n",
      "Processing batch 307, problems 4912 to 4927\n",
      "Processing batch 308, problems 4928 to 4943\n",
      "Processing batch 309, problems 4944 to 4959\n",
      "Processing batch 310, problems 4960 to 4975\n",
      "Processing batch 311, problems 4976 to 4991\n",
      "Processing batch 312, problems 4992 to 5007\n",
      "Processing batch 313, problems 5008 to 5023\n",
      "Processing batch 314, problems 5024 to 5039\n",
      "Processing batch 315, problems 5040 to 5055\n",
      "Processing batch 316, problems 5056 to 5071\n",
      "Processing batch 317, problems 5072 to 5087\n",
      "Processing batch 318, problems 5088 to 5103\n",
      "Processing batch 319, problems 5104 to 5119\n",
      "Processing batch 320, problems 5120 to 5135\n",
      "Processing batch 321, problems 5136 to 5151\n",
      "Processing batch 322, problems 5152 to 5167\n",
      "Processing batch 323, problems 5168 to 5183\n",
      "Processing batch 324, problems 5184 to 5199\n",
      "Processing batch 325, problems 5200 to 5215\n",
      "Processing batch 326, problems 5216 to 5231\n",
      "Processing batch 327, problems 5232 to 5247\n",
      "Processing batch 328, problems 5248 to 5263\n",
      "Processing batch 329, problems 5264 to 5279\n",
      "Processing batch 330, problems 5280 to 5295\n",
      "Processing batch 331, problems 5296 to 5311\n",
      "Processing batch 332, problems 5312 to 5327\n",
      "Processing batch 333, problems 5328 to 5343\n",
      "Processing batch 334, problems 5344 to 5359\n",
      "Processing batch 335, problems 5360 to 5375\n",
      "Processing batch 336, problems 5376 to 5391\n",
      "Processing batch 337, problems 5392 to 5407\n",
      "Processing batch 338, problems 5408 to 5423\n",
      "Processing batch 339, problems 5424 to 5439\n",
      "Processing batch 340, problems 5440 to 5455\n",
      "Processing batch 341, problems 5456 to 5471\n",
      "Processing batch 342, problems 5472 to 5487\n",
      "Processing batch 343, problems 5488 to 5503\n",
      "Processing batch 344, problems 5504 to 5519\n",
      "Processing batch 345, problems 5520 to 5535\n",
      "Processing batch 346, problems 5536 to 5551\n",
      "Processing batch 347, problems 5552 to 5567\n",
      "Processing batch 348, problems 5568 to 5583\n",
      "Processing batch 349, problems 5584 to 5599\n",
      "Processing batch 350, problems 5600 to 5615\n",
      "Processing batch 351, problems 5616 to 5631\n",
      "Processing batch 352, problems 5632 to 5647\n",
      "Processing batch 353, problems 5648 to 5663\n",
      "Processing batch 354, problems 5664 to 5679\n",
      "Processing batch 355, problems 5680 to 5695\n",
      "Processing batch 356, problems 5696 to 5711\n",
      "Processing batch 357, problems 5712 to 5727\n",
      "Processing batch 358, problems 5728 to 5743\n",
      "Processing batch 359, problems 5744 to 5759\n",
      "Processing batch 360, problems 5760 to 5775\n",
      "Processing batch 361, problems 5776 to 5791\n",
      "Processing batch 362, problems 5792 to 5807\n",
      "Processing batch 363, problems 5808 to 5823\n",
      "Processing batch 364, problems 5824 to 5839\n",
      "Processing batch 365, problems 5840 to 5855\n",
      "Processing batch 366, problems 5856 to 5871\n",
      "Processing batch 367, problems 5872 to 5887\n",
      "Processing batch 368, problems 5888 to 5903\n",
      "Processing batch 369, problems 5904 to 5919\n",
      "Processing batch 370, problems 5920 to 5935\n",
      "Processing batch 371, problems 5936 to 5951\n",
      "Processing batch 372, problems 5952 to 5967\n",
      "Processing batch 373, problems 5968 to 5983\n",
      "Processing batch 374, problems 5984 to 5999\n",
      "Processing batch 375, problems 6000 to 6015\n",
      "Processing batch 376, problems 6016 to 6031\n",
      "Processing batch 377, problems 6032 to 6047\n",
      "Processing batch 378, problems 6048 to 6063\n",
      "Processing batch 379, problems 6064 to 6079\n",
      "Processing batch 380, problems 6080 to 6095\n",
      "Processing batch 381, problems 6096 to 6111\n",
      "Processing batch 382, problems 6112 to 6127\n",
      "Processing batch 383, problems 6128 to 6143\n",
      "Processing batch 384, problems 6144 to 6159\n",
      "Processing batch 385, problems 6160 to 6175\n",
      "Processing batch 386, problems 6176 to 6191\n",
      "Processing batch 387, problems 6192 to 6207\n",
      "Processing batch 388, problems 6208 to 6223\n",
      "Processing batch 389, problems 6224 to 6239\n",
      "Processing batch 390, problems 6240 to 6255\n",
      "Processing batch 391, problems 6256 to 6271\n",
      "Processing batch 392, problems 6272 to 6287\n",
      "Processing batch 393, problems 6288 to 6303\n",
      "Processing batch 394, problems 6304 to 6319\n",
      "Processing batch 395, problems 6320 to 6335\n",
      "Processing batch 396, problems 6336 to 6351\n",
      "Processing batch 397, problems 6352 to 6367\n",
      "Processing batch 398, problems 6368 to 6383\n",
      "Processing batch 399, problems 6384 to 6399\n",
      "Processing batch 400, problems 6400 to 6415\n",
      "Processing batch 401, problems 6416 to 6431\n",
      "Processing batch 402, problems 6432 to 6447\n",
      "Processing batch 403, problems 6448 to 6463\n",
      "Processing batch 404, problems 6464 to 6479\n",
      "Processing batch 405, problems 6480 to 6495\n",
      "Processing batch 406, problems 6496 to 6511\n",
      "Processing batch 407, problems 6512 to 6527\n",
      "Processing batch 408, problems 6528 to 6543\n",
      "Processing batch 409, problems 6544 to 6559\n",
      "Processing batch 410, problems 6560 to 6575\n",
      "Processing batch 411, problems 6576 to 6591\n",
      "Processing batch 412, problems 6592 to 6607\n",
      "Processing batch 413, problems 6608 to 6623\n",
      "Processing batch 414, problems 6624 to 6639\n",
      "Processing batch 415, problems 6640 to 6655\n",
      "Processing batch 416, problems 6656 to 6671\n",
      "Processing batch 417, problems 6672 to 6687\n",
      "Processing batch 418, problems 6688 to 6703\n",
      "Processing batch 419, problems 6704 to 6719\n",
      "Processing batch 420, problems 6720 to 6735\n",
      "Processing batch 421, problems 6736 to 6751\n",
      "Processing batch 422, problems 6752 to 6767\n",
      "Processing batch 423, problems 6768 to 6783\n",
      "Processing batch 424, problems 6784 to 6799\n",
      "Processing batch 425, problems 6800 to 6815\n",
      "Processing batch 426, problems 6816 to 6831\n",
      "Processing batch 427, problems 6832 to 6847\n",
      "Processing batch 428, problems 6848 to 6863\n",
      "Processing batch 429, problems 6864 to 6879\n",
      "Processing batch 430, problems 6880 to 6895\n",
      "Processing batch 431, problems 6896 to 6911\n",
      "Processing batch 432, problems 6912 to 6927\n",
      "Processing batch 433, problems 6928 to 6943\n",
      "Processing batch 434, problems 6944 to 6959\n",
      "Processing batch 435, problems 6960 to 6975\n",
      "Processing batch 436, problems 6976 to 6991\n",
      "Processing batch 437, problems 6992 to 7007\n",
      "Processing batch 438, problems 7008 to 7023\n",
      "Processing batch 439, problems 7024 to 7039\n",
      "Processing batch 440, problems 7040 to 7055\n",
      "Processing batch 441, problems 7056 to 7071\n",
      "Processing batch 442, problems 7072 to 7087\n",
      "Processing batch 443, problems 7088 to 7103\n",
      "Processing batch 444, problems 7104 to 7119\n",
      "Processing batch 445, problems 7120 to 7135\n",
      "Processing batch 446, problems 7136 to 7151\n",
      "Processing batch 447, problems 7152 to 7167\n",
      "Processing batch 448, problems 7168 to 7183\n",
      "Processing batch 449, problems 7184 to 7199\n",
      "Processing batch 450, problems 7200 to 7215\n",
      "Processing batch 451, problems 7216 to 7231\n",
      "Processing batch 452, problems 7232 to 7247\n",
      "Processing batch 453, problems 7248 to 7263\n",
      "Processing batch 454, problems 7264 to 7279\n",
      "Processing batch 455, problems 7280 to 7295\n",
      "Processing batch 456, problems 7296 to 7311\n",
      "Processing batch 457, problems 7312 to 7327\n",
      "Processing batch 458, problems 7328 to 7343\n",
      "Processing batch 459, problems 7344 to 7359\n",
      "Processing batch 460, problems 7360 to 7375\n",
      "Processing batch 461, problems 7376 to 7391\n",
      "Processing batch 462, problems 7392 to 7407\n",
      "Processing batch 463, problems 7408 to 7423\n",
      "Processing batch 464, problems 7424 to 7439\n",
      "Processing batch 465, problems 7440 to 7455\n",
      "Processing batch 466, problems 7456 to 7471\n",
      "Processing batch 467, problems 7472 to 7487\n",
      "Processing batch 468, problems 7488 to 7503\n",
      "Processing batch 469, problems 7504 to 7519\n",
      "Processing batch 470, problems 7520 to 7535\n",
      "Processing batch 471, problems 7536 to 7551\n",
      "Processing batch 472, problems 7552 to 7567\n",
      "Processing batch 473, problems 7568 to 7583\n",
      "Processing batch 474, problems 7584 to 7599\n",
      "Processing batch 475, problems 7600 to 7615\n",
      "Processing batch 476, problems 7616 to 7631\n",
      "Processing batch 477, problems 7632 to 7647\n",
      "Processing batch 478, problems 7648 to 7663\n",
      "Processing batch 479, problems 7664 to 7679\n",
      "Complete! All responses saved to model_responses.csv\n",
      "Loading back into a dataset...\n",
      "Dataset loaded with 15360 examples\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import csv\n",
    "import gc\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Define output file\n",
    "output_file = \"model_responses.csv\"\n",
    "problems = initial_dataset['train']['problem'][:7680]\n",
    "\n",
    "del initial_dataset\n",
    "\n",
    "# Create CSV file with headers\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['problem', 'text', 'model'])\n",
    "\n",
    "def process_and_save_batch(batch_problems, batch_index, batch_size):\n",
    "    \"\"\"Process a batch and save results directly to CSV\"\"\"\n",
    "    try:\n",
    "        print(f\"Processing batch {batch_index}, problems {batch_index*batch_size} to {batch_index*batch_size + len(batch_problems) - 1}\")\n",
    "        \n",
    "        # Move R1 model to GPU and generate responses\n",
    "        r1_model.to('cuda')\n",
    "        r1_responses = batch_get_responses(r1_model, batch_problems, batch_size=batch_size, add_think=True)\n",
    "        r1_model.to('cpu')\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Move Qwen model to GPU and generate responses\n",
    "        qwen_model.to('cuda')\n",
    "        qwen_responses = batch_get_responses(qwen_model, batch_problems, batch_size=batch_size)\n",
    "        qwen_model.to('cpu')\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Write results to CSV\n",
    "        with open(output_file, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            \n",
    "            for problem, r1_resp, qwen_resp in zip(batch_problems, r1_responses, qwen_responses):\n",
    "                # Write R1 response\n",
    "                writer.writerow([problem, r1_resp, 'r1'])\n",
    "                \n",
    "                # Write Qwen response\n",
    "                writer.writerow([problem, qwen_resp, 'qwen'])\n",
    "        \n",
    "        # Clean up\n",
    "        del r1_responses, qwen_responses\n",
    "        gc.collect()\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {batch_index}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Process all problems in batches\n",
    "batch_size = 16  # Start with a small batch size\n",
    "total_batches = (len(problems) + batch_size - 1) // batch_size\n",
    "\n",
    "with tqdm(total=total_batches, desc=\"Processing batches\") as pbar:\n",
    "    for batch_index in range(total_batches):\n",
    "        start_idx = batch_index * batch_size\n",
    "        end_idx = min(start_idx + batch_size, len(problems))\n",
    "        batch_problems = problems[start_idx:end_idx]\n",
    "        \n",
    "        # Process batch and save to CSV\n",
    "        success = process_and_save_batch(batch_problems, batch_index, batch_size)\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"Failed to process batch {batch_index}, skipping to next batch\")\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "# Once complete, you can load the CSV back into a dataset if needed\n",
    "print(f\"Complete! All responses saved to {output_file}\")\n",
    "print(f\"Loading back into a dataset...\")\n",
    "\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "combined_dataset = Dataset.from_pandas(pd.read_csv(output_file))\n",
    "print(f\"Dataset loaded with {len(combined_dataset)} examples\")\n",
    "# sort by problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetDict' object has no attribute 'train_test_split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# split test and train 90 10\u001b[39;00m\n\u001b[1;32m      2\u001b[0m test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m----> 3\u001b[0m combined_dataset \u001b[38;5;241m=\u001b[39m combined_dataset\u001b[38;5;241m.\u001b[39mtrain_test_split(\n\u001b[1;32m      4\u001b[0m     test_size\u001b[38;5;241m=\u001b[39mtest_size,\n\u001b[1;32m      5\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#combined_dataset = combined_dataset.sort('problem')\u001b[39;00m\n\u001b[1;32m     10\u001b[0m combined_dataset\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannasoli/r1qw_numinamath_test_train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetDict' object has no attribute 'train_test_split'"
     ]
    }
   ],
   "source": [
    "# split test and train 90 10\n",
    "test_size = 0.1\n",
    "combined_dataset = combined_dataset.train_test_split(\n",
    "    test_size=test_size,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "#combined_dataset = combined_dataset.sort('problem')\n",
    "combined_dataset.push_to_hub('annasoli/r1qw_numinamath1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080e154ce6a540628efc39cbbf2b1037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3928956d2a074152b8fea514085ac605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0debaa4e63594e639e328095473b35b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0748223b866485181bf7996493d1860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05dbe5db3ad41059f8df9675e276b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/annasoli/r1qw_numinamath1/commit/3ef6b3bd8081ab8b6c02ec8d358603c61b764b2c', commit_message='Upload dataset', commit_description='', oid='3ef6b3bd8081ab8b6c02ec8d358603c61b764b2c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/annasoli/r1qw_numinamath1', endpoint='https://huggingface.co', repo_type='dataset', repo_id='annasoli/r1qw_numinamath1'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load dataset\n",
    "dataset = load_dataset('annasoli/r1qw_numinamath')\n",
    "dataset.push_to_hub('annasoli/r1qw_numinamath1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
